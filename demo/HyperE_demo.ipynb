{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.sparse.csgraph import floyd_warshall, connected_components\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some definitions\n",
    "\n",
    "# Reflection (circle inversion of x through orthogonal circle centered at a)\n",
    "def isometric_transform(a, x):\n",
    "    r2 = np.linalg.norm(a)**2 - (1.0)\n",
    "    return r2/np.linalg.norm(x - a)**2 * (x-a) + a\n",
    "\n",
    "# Inversion taking mu to origin\n",
    "def reflect_at_zero(mu,x):\n",
    "    a = mu/np.linalg.norm(mu)**2\n",
    "    return isometric_transform(a,x)\n",
    "\n",
    "def acosh(x):\n",
    "    return np.log(x + np.sqrt(x**2-1))\n",
    "\n",
    "# Hyperbolic distance\n",
    "def dist(u,v):\n",
    "    z  = 2 * np.linalg.norm(u-v)**2\n",
    "    uu = 1. + z/((1-np.linalg.norm(u)**2)*(1-np.linalg.norm(v)**2))\n",
    "    return acosh(uu)\n",
    "\n",
    "# Hyperbolic distance from 0\n",
    "def hyp_dist_origin(x):\n",
    "    return np.log((1+np.linalg.norm(x))/(1-np.linalg.norm(x)))\n",
    "\n",
    "# Scalar multiplication w*x\n",
    "def hyp_scale(w, x):\n",
    "    sgn = (-1.0)**float(w<0)\n",
    "    w *= sgn    \n",
    "    if w == 1:\n",
    "        return sgn*x\n",
    "    else:\n",
    "        x_dist = (1+np.linalg.norm(x))/(1-np.linalg.norm(x))\n",
    "        alpha = 1-2/(1+x_dist**w)\n",
    "        alpha *= 1/np.linalg.norm(x)\n",
    "    \n",
    "    return sgn*alpha*x\n",
    "\n",
    "# Convex combination (1-w)*x+w*y\n",
    "def hyp_conv_comb(w, x, y):\n",
    "    # circle inversion sending x to 0\n",
    "    (xinv, yinv) = (reflect_at_zero(x, x), reflect_at_zero(x, y))\n",
    "    # scale by w \n",
    "    pinv = hyp_scale(w, yinv)\n",
    "    # reflect back\n",
    "    return reflect_at_zero(x, pinv)\n",
    "\n",
    "# Weighted sum w1*x + w2*y\n",
    "def hyp_weighted_sum(w1, w2, x, y):\n",
    "    p = hyp_conv_comb(w2 / (w1 + w2), x, y)\n",
    "    return hyp_scale(w1 + w2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the edge list for hypernym relationship in Wordnet.\n",
    "\n",
    "def load_wordnet():\n",
    "    SynstoIDs  = dict()\n",
    "    IDstoSyns = dict()\n",
    "    all_syns = list(wn.all_synsets())\n",
    "    \n",
    "    for idx, x in enumerate(all_syns):\n",
    "        SynstoIDs[x] = idx\n",
    "        IDstoSyns[idx] = x\n",
    "\n",
    "    n = len(all_syns)\n",
    "    e = make_edge_set()\n",
    "\n",
    "    for idx, x in enumerate(all_syns):\n",
    "        for y in x.hypernyms():\n",
    "            y_idx = SynstoIDs[y]\n",
    "            add_edge(e, idx  , y_idx)\n",
    "            add_edge(e, y_idx,   idx)\n",
    "            \n",
    "    X = csr_matrix(e, shape=(n, n))\n",
    "\n",
    "    return SynstoIDs, IDstoSyns, X, all_syns\n",
    "\n",
    "    \n",
    "SynstoIDs, IDstoSyns, X, all_syns = load_wordnet()\n",
    "G = nx.from_scipy_sparse_matrix(X)\n",
    "Gc = max(nx.connected_component_subgraphs(G), key=len)\n",
    "\n",
    "# reorder with nx\n",
    "Gc_final = nx.convert_node_labels_to_integers(Gc, ordering=\"decreasing degree\", label_attribute=\"old_label\")\n",
    "\n",
    "#Create the dict for old-id <-> new-id matching for syns\n",
    "RefDict = Gc_final.node\n",
    "IDsToSyns_f = dict()\n",
    "SynsToIDs_f = dict()\n",
    "for new_idx in RefDict.keys():\n",
    "    old_idx = RefDict[new_idx]['old_label']\n",
    "    curr_syn = IDstoSyns[old_idx]\n",
    "    IDsToSyns_f[new_idx] = curr_syn\n",
    "    SynsToIDs_f[curr_syn] = new_idx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the emb files, save their tau and emb_dict.\n",
    "\n",
    "emb_files = {\n",
    "            'hypernym_demo.emb':'hypernym_demo',\n",
    "            }\n",
    "\n",
    "RelEmbDict = defaultdict(dict)\n",
    "RelTauDict = defaultdict(dict)\n",
    "for file in emb_files.keys():\n",
    "    with open(file, 'r') as emb:\n",
    "        emb_lines = emb.readlines()    \n",
    "    emb_lines = emb_lines[1:]\n",
    "    emb_dict = dict()\n",
    "    rel = emb_files[file]\n",
    "    for idx, line in enumerate(emb_lines):\n",
    "        curr_line = line.split(',')\n",
    "        curr_tau = curr_line[-1].split(\"\\n\")[0]\n",
    "        curr_tau = np.float64(curr_tau)\n",
    "        curr_line = curr_line[:-1]\n",
    "        curr_idx = int(curr_line[0])                \n",
    "        emb_dict[curr_idx] = np.asarray(list(map(np.float64, curr_line[1:])))\n",
    "    RelEmbDict[rel] = emb_dict\n",
    "    RelTauDict[rel] = curr_tau\n",
    "    \n",
    "\n",
    "#Construct W matrices for each relationship separately. \n",
    "    \n",
    "vector_dim = 10\n",
    "ReltoW = defaultdict()\n",
    "for rel in RelEmbDict.keys():\n",
    "    emb_dict_curr = RelEmbDict[rel]\n",
    "    vocab_size = len(emb_dict_curr)\n",
    "    W_curr = np.zeros((vocab_size, vector_dim))\n",
    "    for idx, vec in emb_dict_curr.items():\n",
    "        W_curr[idx,:] = vec\n",
    "    ReltoW[rel] = W_curr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999957925 non-euclidean_geometry.n.01 (mathematics) geometry based on axioms different from Euclid's\n",
      "0.999999990071 plane_geometry.n.01 the geometry of 2-dimensional figures\n",
      "0.999999994248 solid_geometry.n.01 the geometry of 3-dimensional space\n",
      "0.999999994509 fractal_geometry.n.01 (mathematics) the geometry of fractals\n",
      "1.00000000061 pure_mathematics.n.01 the branches of mathematics that study and develop the principles of mathematics for their own sake rather than for their immediate usefulness\n",
      "1.00000000189 spherical_geometry.n.01 (mathematics) the geometry of figures on the surface of a sphere\n",
      "1.00000000937 projective_geometry.n.01 the geometry of properties that remain invariant under projection\n",
      "1.0000000101 analytic_geometry.n.01 the use of algebra to study geometric properties; operates on symbols defined in a coordinate system\n",
      "1.00000001566 affine_geometry.n.01 the geometry of affine transformations\n",
      "1.00000002831 elementary_geometry.n.01 (mathematics) geometry based on Euclid's axioms\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 nearest neighbors to a particular synset for given relationship.\n",
    "\n",
    "vector_dim = 10\n",
    "rel = 'hypernym_demo'\n",
    "emb_dict_curr = RelEmbDict[rel]\n",
    "vocab_size = len(emb_dict_curr)\n",
    "W = np.zeros((vocab_size, vector_dim))\n",
    "relTau = RelTauDict[rel]\n",
    "\n",
    "\n",
    "e1 = wn.synset('geometry.n.01')\n",
    "e1_idx = SynsToIDs_f[e1]\n",
    "\n",
    "\n",
    "for idx, vec in emb_dict_curr.items():\n",
    "    W[idx,:] = vec\n",
    "    \n",
    "vec_e1 = emb_dict_curr[e1_idx] \n",
    "curr_dist = []    \n",
    "for row_idx in range(W.shape[0]):\n",
    "    curr_vec = W[row_idx,:]\n",
    "    normalized_dist = (dist(curr_vec,vec_e1))/relTau\n",
    "    curr_dist.append(normalized_dist)\n",
    "\n",
    "\n",
    "curr_dist[e1_idx] = np.Inf\n",
    "curr_closest_indices = np.argsort(curr_dist)[:10]\n",
    "for r_idx in curr_closest_indices:\n",
    "    relev_syn = IDsToSyns_f[r_idx]\n",
    "    print(curr_dist[r_idx], relev_syn.name(), relev_syn.definition())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716374331939 writer.n.01 writes (books or stories or articles or the like) professionally (for pay)\n",
      "0.987304286504 communicator.n.01 a person who communicates with others\n",
      "1.17175459928 librettist.n.01 author of words to be set to music in an opera or operetta\n",
      "1.18552618387 announcer.n.01 someone who proclaims a message publicly\n",
      "1.18607557487 essayist.n.01 a writer of literary works\n",
      "1.20045196565 commentator.n.02 a writer who reports and analyzes events of the day\n",
      "1.21288127055 gagman.n.02 someone who writes comic material for public performers\n",
      "1.21336310414 sympathizer.n.01 commiserates with someone who has had misfortune\n",
      "1.25372619738 lyricist.n.01 a person who writes the words for songs\n",
      "1.26142195216 alliterator.n.01 a speaker or writer who makes use of alliteration\n"
     ]
    }
   ],
   "source": [
    "# Word analogy for selected examples.\n",
    "\n",
    "vector_dim = 10\n",
    "rel = 'hypernym_demo'\n",
    "emb_dict_curr = RelEmbDict[rel]\n",
    "vocab_size = len(emb_dict_curr)\n",
    "W = np.zeros((vocab_size, vector_dim))\n",
    "relTau = RelTauDict[rel]\n",
    "\n",
    "\n",
    "# Choose the entities.\n",
    "e1 = wn.synset('guitarist.n.01')\n",
    "e1_idx = SynsToIDs_f[e1]\n",
    "\n",
    "e2 = wn.synset('musician.n.01')\n",
    "e2_idx = SynsToIDs_f[e2]\n",
    "\n",
    "e3 = wn.synset('novelist.n.01')\n",
    "e3_idx = SynsToIDs_f[e3]\n",
    "\n",
    "\n",
    "for idx, vec in emb_dict_curr.items():\n",
    "    W[idx,:] = vec\n",
    "    \n",
    "vec_e1 = emb_dict_curr[e1_idx]\n",
    "vec_e2 = emb_dict_curr[e2_idx]\n",
    "vec_e3 = emb_dict_curr[e3_idx]\n",
    "\n",
    "\n",
    "vec1_ = hyp_scale(-1, vec_e1)\n",
    "left_sum = hyp_weighted_sum(1, 1, vec_e2, vec1_)\n",
    "vec_search = hyp_weighted_sum(1, 1, left_sum, vec_e3)\n",
    "\n",
    "curr_dist = []    \n",
    "for row_idx in range(W.shape[0]):\n",
    "    curr_vec = W[row_idx,:]\n",
    "    normalized_dist = (dist(curr_vec, vec_search))/relTau\n",
    "    curr_dist.append(normalized_dist)\n",
    "\n",
    "\n",
    "curr_dist[e1_idx] = np.Inf\n",
    "curr_dist[e2_idx] = np.Inf\n",
    "curr_dist[e3_idx] = np.Inf\n",
    "\n",
    "curr_closest_indices = np.argsort(curr_dist)[:10]\n",
    "for r_idx in curr_closest_indices:\n",
    "    relev_syn = IDsToSyns_f[r_idx]\n",
    "    print(curr_dist[r_idx], relev_syn.name(), relev_syn.definition())\n",
    "\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
